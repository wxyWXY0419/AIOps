cand = """
## POSSIBLE ROOT CAUSE COMPONENTS:
- cartservice-0
- currencyservice-1
- currencyservice-0
- frontend-2
- frontend-0
- frontend-1
- recommendationservice-2
- adservice-0
- shippingservice-0
- cartservice-1
- cartservice-2
- checkoutservice-0
- currencyservice-2
- recommendationservice-1
- shippingservice-1
- shippingservice-2
- checkoutservice-2
- paymentservice-0
- paymentservice-2
- paymentservice-1
- emailservice-1
- emailservice-2
- emailservice-0
- redis-cart-0
- adservice-1
- adservice-2"""

schema = f"""## DATASET STRUCTURE:

- You can access the data directory in our microservices system: `dataset/phaseone/`.

- This directory contains subdirectories organized by a date (e.g., `dataset/phaseone/2025-06-06/`). 

- Within each date-specific directory, you'll find these subdirectories: `metric-parquet`, `trace-parquet`, and `log-parquet` (e.g., `dataset/phaseone/2025-06-06/metric-parquet/`).

- The data in `trace-parquet` and `log-parquet` subdirectories is stored in parquet format (e.g., `dataset/phaseone/2025-06-06/log-parquet/log_filebeat-server_2025-06-06_00-00-00.parquet`).

- Within 'metric-parquet' directory, you will find these subdirectories: `apm`, `infra` and `other`(e.g., `dataset/phaseone/2025-06-06/metric-parquet/apm`).

- For `metric-parquet` subdirectory, the internal data folder structure is shown below:

```plaintext
dataset/phaseone/2025-06-06/metric-parquet/
├── apm/
│   ├── pod/
|   |   ├── pod_adservice-0_2025-06-06.parquet
│   |   └── ...
|   ├── service/
|   |   ├── service_adservice_2025-06-06.parquet
|   |   └── ...
│   └── pod_ns_hipstershop_2025-06-06.parquet
├── infra/
│   ├── infra_node/
|   |   └── infra_node_node_cpu_usage_rate_2025-06-06.parquet
|   ├── infra_pod/
|   |   └── infra_pod_pod_cpu_usage_2025-06-06.parquet
│   └── infra_tidb/
|       └── infra_tidb_block_cache_size_2025-06-06.parquet
└── other/
|   ├── infra_pd_abnormal_region_count_2025-06-06.parquet
    └── ...
```

## DATA SCHEMA

1.  **Metric Files** (in metric-parquet/):
    
    1. `apm/pod/*.parquet`:
        ```csv
        timestamp,pod_name,value
        1687035600,checkoutservice-0,0.15
        ```
        - pod级别的APM指标数据
        - value代表具体指标值(如CPU使用率、内存使用量等)

    2. `apm/service/*.parquet`:
        ```csv
        timestamp,service_name,value
        1687035600,checkoutservice,0.25
        ```
        - service级别的APM指标数据
        - value表示服务级别的性能指标

    3. `infra/infra_node/*.parquet`:
        ```csv
        timestamp,node,value
        1687035600,aiops-k8s-01,45.2
        ```
        - 节点级别的基础设施指标
        - value表示节点资源使用情况

2.  **Trace Files** (in trace-parquet/):
    ```csv
    timestamp,trace_id,span_id,parent_span_id,service,operation,duration,status
    1687035602123,abc123,span1,parent1,frontend,HTTP GET,150,OK
    ```
    - timestamp: 毫秒级时间戳
    - service: 服务名称
    - operation: 操作名称
    - duration: 调用耗时(ms)
    - status: 调用状态

3.  **Log Files** (in log-parquet/):
    ```csv
    timestamp,service,level,content
    1687035600,checkoutservice,ERROR,"Connection refused to database"
    ```
    - timestamp: 秒级时间戳, **UTC**
    - service: 产生日志的服务名称
    - level: 日志级别(INFO/WARN/ERROR等)
    - content: 日志具体内容

## 时间说明(IMPORTANT):
1. 在读取的imput中异常描述(Anomaly Description)中的时间是 UTC 时间
2. 数据文件名使用 UTC+8 (北京时间)
3. 时间转换规则：
   - 例如:异常发生时间 2025-06-05T16:10:02Z (UTC)
   - 对应的文件时间为 2025-06-06 (UTC+8)
   - 转换方法:UTC 时间 + 8小时 = 文件名中的时间

4. 数据读取时的时间处理：
   - 首先根据异常时间确定需要读取哪一天的数据文件
   - UTC 时间需要 +8 小时才能对应到正确的数据文件
   - 示例：
     * 异常时间:2025-06-05T16:10:02Z (UTC)
     * 对应文件:dataset/phaseone/2025-06-06/... (因为 16:10:02 + 8 = 00:10:02,是第二天了)

## 补充说明:

1. 所有时间戳相关说明:
   - metric数据: 秒级时间戳, UTC时间
   - log数据: 秒级时间戳, UTC时间
   - trace数据中的startTimeMillis: 毫秒级时间戳

2. 服务命名规则:
   - checkoutservice
   - orderservice
   - paymentservice 
   - 等标准服务名称

3. 数据采样周期:
   - metrics: 60秒/次
   - traces: 实时采集
   - logs: 实时采集


{cand}

## CLARIFICATION OF TELEMETRY DATA:

1. This dataset is generated by builted microservice system.

2. File Name Time Format:
   - Using CST timezone (UTC+8)
   - Example: log_filebeat-server_2025-06-06_00-00-00.parquet
   - Represents 00:00:00 on June 6, 2025 in Beijing time

3. In different data files, the timestamp formats vary:

   - Metric Data:
     Format: 2025-06-05T16:00:00Z (UTC timezone)
     Example: 2025-06-05T16:00:00Z equals to 2025-06-06 00:00:00 in Beijing time

   - Log Data: 
     Format: 2025-06-05T16:00:29.045Z (UTC timezone)
     Example: 2025-06-05T16:00:29.045Z equals to 2025-06-06 00:00:29.045 in Beijing time

   - Trace Data:
     Format: Unix timestamp in milliseconds
     Example: 1749139200377 (startTimeMillis field)

4. Timezone Conversion Notes:
   - File names use Beijing time (CST/UTC+8)
   - Data content uses UTC time
   - All timestamps are in UTC
   - For analysis: UTC+8 = Beijing time
"""

import pytz
from datetime import datetime

def convert_utc_to_file_date(utc_time_str):
    # 解析 UTC 时间字符串
    utc_time = datetime.strptime(utc_time_str.rstrip('Z'), '%Y-%m-%dT%H:%M:%S')
    # 转换到 UTC+8
    beijing_tz = pytz.timezone('Asia/Shanghai')
    beijing_time = pytz.utc.localize(utc_time).astimezone(beijing_tz)
    # 返回对应的文件日期
    return beijing_time.strftime('%Y-%m-%d')

# 示例：从异常描述中提取日期
def extract_date_from_description(description):
    # 使用正则表达式从描述中提取日期
    import re
    match = re.search(r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z)', description)
    if match:
        return convert_utc_to_file_date(match.group(1))
    return None

# 使用示例
# description = "The system experienced an anomaly from 2025-06-05T16:10:02Z to 2025-06-05T16:31:02Z. Please infer the possible cause."
# date_str = extract_date_from_description(description)
# print(date_str)  # 输出: 2025-06-06